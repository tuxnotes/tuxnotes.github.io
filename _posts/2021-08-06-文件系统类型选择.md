---
layout: post
title: 文件系统类型选择
author: tux
date: 2021-08-06
tags: Linux
---
为应用选择合适的RHEL文件系统是一项重要的决定，因为存在大量的可选类型以及需要权衡考虑。本文描述了RHEL提供的一些文件系统，给出了历史背景，并推荐了适合你应用的文件系统。

# 1 文件系统的类型
RHEL支持多种文件系统，不同类型的文件系统解决不同的类型的问题，并且其使用场景是应用特定的。在多数的通用水平下，RHEL中的文件系统可分为如下几个大类：

- 磁盘或本地文件系统
- 网络或C/S文件系统
- 共享存储或共享文件系统
- 特殊文件系统

# 2 本地文件系统总览

本地文件系统运行于单个本地的服务器。比如对于S-ATA或SAS磁盘，内部文件系统是唯一的选择，并可以与RAID控制器一起使用。本地文件系统也常用于SAN附件存储，当SAN的export设备不共享的时候。

RHEL 4和RHEL 5平台提供两种传统的文件系统，ext2和ext3。ext文件系统家族的最新版ext4，从RHEL5.6开始完全支持。

所有的这些文件系统都是POSIX兼容的，并且兼容RHEL后续的发行版。POSIX兼容的文件系统提供了完善的系统调用支持，如`read()`,`write()`和`seek()`。从程序员的角度，基本没有区别。从用户的角度，最明显的不同就是扩展或性能相关的问题。在考虑选择文件系统的时候，你应该考虑文件系统需要多大，以及文件系统需要具有的特殊特定，和在你的负载下的性能表现。

# 3 XFS文件系统

XFS文件系统是强大的成熟的64-bit的日志文件系统，单机上支持非常大的文件和文件系统。它是RHEL7的默认文件系统。日志记录保证了系统崩溃时候文件系统的完整性，比如因为断电。通过保存的文件系统的操作记录，在系统重启后，在重新挂在文件系统后重放这些操作达到文件的完整性。XFS是在1990年早起有SGI开发的，并在极大的服务器和存储阵列上运行了较长的时间。XFS支持的特性如下：

- delayed allocation延迟分配
- dynamically allocated inodes
- B-tree indexing for scalability of free space management用于空闲空间管理的b-tree索引
- ability to support a large number of concurrent operations支持大量并发操作
- extensive run-time metadata consistency checking
- sophisticated metadata read-ahead algorithms
- tightly integrated backup and restore utilities
- online defragmentation
- online filesystem growing
- comprehensive diagnostics capabilities
- scalable and fast repair utitlies
- optimizations for streaming video workloads

XFS可以扩展到exabytes，RHEL5支持的最大XFS文件系统镜像是100TB，RHEL6是300TB，RHEL7是500TB。考虑到环境高性能和可扩展的需求长期历史，就不难发现XFS可以作为企业级高性能的文件系统。比如，大的系统一般都配备了较多的CPU，多HBA链接到外部存储阵列。XFS在多线程，并行IO的小型系统的性能也表现良好。对于单线程，元数据密集型工作负载，XFS性能相对较差。比如工作负载在单线程中删除大量的许多小文件。最后，你不能缩小XFS文件系统的尺寸，因此你需要格外小心，分配空间不要超过文件系统现存空间大小。

- 关于缩减的XFS文件系统的更多信息，参考[How to reduce XFS file system](https://access.redhat.com/solutions/540013)
- 关于文件系统，文件，目录大小限制的相信信息参考[Red Hat Enterprise Linux technology capabilities and limits](https://access.redhat.com/articles/rhel-limits)

# 4 Ext文件系统家族

## 4.1 Ext4文件系统

Ext4是ext文件系统家族的第四代，在RHEL6中是默认的文件系统。ext4可以读写ext2和ext3文件系统，但是ext4文件系统格式与ext2和ext3驱动并不兼容。但是ext4增加了一些新特性以及一些增强特性，比如：
- extent-based metadata
- delayed allocation
- journal checksumming
- Large storage support

ext4使用extent-based metadata实现了更加简洁和高效的方式来追踪文件系统的使用空间，同时也实现了delayed allocation的特性。这些特性提高了文件系统的性能，并减少了metadata占用的空间。delayed allocation允许文件系统延迟新写入用户数据存储位置的选择，直到数据需要flash到磁盘的时候。这使得ext4有较高的性能，因为它允许较大，更连续的分配，允许文件系统根据更有用的信息做出决定。

ext4的文件系统修复(fsck)比ext3和ext2更快。一些文件系统的修复已经证明了性能上增加了6倍。ext4在RHEL5和RHEL6上支持最大为16TB，RHEL7为50TB。

你可以缩小ext4和ext3文件系统，所以在存储分配上提供了更多的灵活性。

# 5 本地文件系统选择

如果选择文件系统来满足应用的需求？第一步是要理解你要部署文件系统的目标系统。下面的问题可以帮助你做决定：

- Do you have a large server?
- Do you have large storage requiements or have a local, slow S-ATA drive?
- what kind of I/O workload do you expect your application to present?
- what are your throughput and latency requirements?
- How stable is your server and storage hardware?
- what is the typical size of your files and data set?
- if the system fails, how much downtime can you suffer?
- Do you foresee the need to shrink(reduce) the file system size?

根据以上问题的不同回答，选择也不同。如果你的服务器和存储设备都很大，且不需要缩减文件系统大小，则XFS是最好的选择。即便是较小的存储阵列，XFS在平均文件大小较大(比如几百MB)的时候表现也是可以的。

如果现存工作负载在ext3上性能良好，那么要么保持ext3或者是迁移到ext4都会给应用提供一个熟悉的环境。在同一存储上，ext4优于ext3的两个关键方面：1. 较快的文件系统检查和回复速度；2. 在告诉的磁盘上有较高的流式读写性能。

ext4文件系统在I/O能力有限的系统上表现更好。ext3和ext4在受限带宽(<200MB/s)表现更好，可高达1000IOPS的能力。对于其他更高的能力，则XFS表现更好。XFS对每次的metadata操作消耗的CPU是ext3和ext4的两倍，因此如果你的负载是CPU密集性的，且并发不大，则ext3或ext4会更快速。总体来说，ext3或ext4适用于单线程读写小文件，二XFS适用于多线程读写大文件。

建议在目标服务器或目标存储上测量你的应用的性能，以确保选择适合应用的文件系统。

# 6 网络文件系统
网络文件系统指的是client/server架构的文件系统。允许客户机访问存储在共享服务器上的文件。这实现了多台机器上的多个用户分享文件和存储资源。这样的文件系统构建于多个服务器之上，并输出给一个或多个client一些文件系统。client不需要访问底层的快存储，而是通过一个协议与存储进行交互。这些系统使用L2网络技术如Gigabit Ethernet来提供充分的性能。
RHEL客户最常用的client/server文件系统是NFS文件系统。RHEL同时提供了服务端和客户端。服务端通过网络输出本地的文件系统，客户端输入这些系统。
RHEL还包含了CIFS客户端，用于支持Microsoft SMB文件服务，用于与Windows结合。为了在RHEL服务器上给Windows客户端提供Microsoft SMB服务，RHEL提供了userspace Samba server。

# 7 共享存储文件系统
shared storage file systems有时指的是集群文件系统，通过local storage area network（SAN），集群中的每个服务器都能直接访问共享的块设备。与前面提到的C/S文件系统类似，共享存储文件系统工作多个服务器之上，这些服务器是集群的成员。与NFS不同的是，没有单个服务器为其他成员提供访问数据或元数据；集群中的每个成员都能访问相同的存储设备("共享存储"),并且所有的集群成员节点访问相同的文件。

缓存聚合性，对于一个集群的文件系统是至关重要的，它保证了数据的连续性和完整性。集群中的所有文件必须有一个版本，对其群的其他节点是可见的。为了阻止集群的成员同事共享相同的存储块而导致的数据崩溃，共享存储文件系统使用了集群锁机制，来处理并发控制访问。比如，在创建一个新文件或者写入一个在多个服务器上打开的文件之前，在服务器的文件系统程序必须获得正确的锁。

集群文件系统的要求提供一个高可用的服务，类似与Apache的web服务。集群中的任何一个成员都能看到一个完整的数据存储全景，所有的更新通过集群锁机制管控。共享磁盘文件系统的性能通常会低于运行于本地的文件系统，因为它需要锁的开销。当每个节点需要写入类似专用的一些文件时，这些文件对其他节点不是共享或者集群范围内只读，此时共享存储文件系统系统表现良好。搭建共享磁盘文件系统非常复杂，并且应用调优也是非常有挑战的。

对于RHEL的客户，Red Hat在RHEL4的时候提供了GFS1，并在RHEL6及以后就不在支持GFS1了。从RHEL5.4开始GFS2就可用了。

# 8 在网络文件系统与共享存储文件系统间做选择
在提供了NFS服务器的环境中，基于NFS的网络文件系统非常常见和流行。需要注意的是网络文件系统可以使用高性能的网络技术如Infiniband or 10 Gigabit Ethernet部署。这意味着用户不需要共享存储文件系统就能使用存储的原始带宽。如果访问速度优先重要，使用NFS输出本地的文件系统。

共享存储文件系统不容易搭建和维护，因此当本地文件系统和网络文集系统不能满足需要的时候可以考虑部署共享存储文件系统。以集群形式的共享存储网络系统有助于减少downtime时长，因为它减少了卸载和挂在操作。当需要提供高可用的服务，downtime时间短，有较高服务水平要求的时候，推荐使用共享存储文件系统。

# 9 结论

选择使用具体应用的文件系统需要咨询很多参数。本文目的是列出各种文件系统适用场景的大纲，帮助用户在特定应用环境中选择正确的文件系统。相信信息咨询Red Hat Support.

# Reference

- https://access.redhat.com/articles/3129891
- https://docs.docker.com/storage/storagedriver/select-storage-driver/
