---
layout: post
title: waht is a data pipeline
date: 2020-09-02
author: tux
tags: data pipeline
---

原文链接：https://dzone.com/articles/what-is-a-data-pipeline

# What is a data pipeline

当今数据流动(如从一个SaaS应用到数据仓库)的效率对于数据驱动型企业来说是至关重要的操作之一。毕竟只有在数据到达之后才能进行任何其他的分析工作。数据流动的操作是有一定风险的，因为数据在从一个
系统传输到另一个系统的过程中可能会出现各种错误：如数据不完整，到达瓶颈导致的延迟，数据源冲突或数据重复等。随着需求的复杂性，数据源数量的多样性的增加，问题会更加突出和放大。

# The Data Pipeline: Built for Efficiency

数据管道软件取消了数据流动过程中的人工操作，使整个流程变得更加平滑和自动。其起始于对采集什么数据，从哪里采集，如何采集这几个问题的定义。数据管道使得数据的提取，清洗，验证，以及用于分析和展示
的数据加载过程变得自动化。一次可以处理多种数据流。简而言之，数据管道对于当今数据驱动型企业是刚需。

数据管道视所有数据为流式数据，不管数据是来自静态的数据源，还是来自实时数据源如在线零售交易，数据管道将数据流划分为更小的数据块，以便它能以并行的方式处理。数据管道并不要求终点是数据仓库。它
可以将数据路由到其他应用，如可视化工具或Salesforce。将其比作组装流水线更加形象。

# How Is a Data Pipeline Different From ETL?

ETL代表![Extract,Transform,Load](https://dzone.com/articles/what-is-etl).ETL系统将数据从一个系统中抽取，然后进行数据加工，最后将数据加载至数据库或数据仓库。传统的ETL一般是以批量的方式
运行，这意味着在固定的时间将大量数据转移到另一个系统。

相反，data pipeline的定义更加广泛，它包含了ETL。它指的是把数据从一个系统转移到另一个系统的系统。数据可能会被加工，也可能不会加工。也可能以实时(流式)的方式而不是批量的方式运行。数据一旦被流式化
那就可以以一种连续的方式流动，这种方式对于数据的持续更新是非常有用的，如来自监控传感器的数据。并且数据并不会加载至数据库或数据仓库。它可以将数据加载至任何目标，如AWS bucket或data lake。甚至于
可以其他系统上触发webhook来取消一个特定的交易过程。

# Who Needs a Data Pipeline?

当然并不是每个企业都需要数据管道的，下面的场景，使用数据管道视非常有益的：

- 生成，依赖，存储大量数据或多个数据源
- 维护数据仓库
- 实时性要求或高级数据分析
- 在云端存储数据

# Types of Data Pipeline Solutions

数据管道有多种方案，不同方案适用于不同目的。下面列出了一些比较常用的方案，需要指出的是这些方案并不是孤立的，可以根据实际情况优化：

- Batch。当数据量非常大，且以一定时间间隔，不要求实时的情况下进行数据移动的时候，批量处理非常有用。如将市场数据导入分析系统。
- Real-time。
- Cloud native。
- Open source。
